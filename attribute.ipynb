{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attribute.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMDzOOf2P4V82EUoj99i6zN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zqp563830312/gitskillls/blob/master/attribute.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbjO3Ep4Qi_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "5a94bedd-883d-49e8-ffde-b0e3777e08f6"
      },
      "source": [
        "!git clone https://github.com/yilifzf/BDCI_Car_2018.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'BDCI_Car_2018'...\n",
            "remote: Enumerating objects: 256, done.\u001b[K\n",
            "remote: Total 256 (delta 0), reused 0 (delta 0), pack-reused 256\u001b[K\n",
            "Receiving objects: 100% (256/256), 83.21 MiB | 25.43 MiB/s, done.\n",
            "Resolving deltas: 100% (37/37), done.\n",
            "Checking out files: 100% (268/268), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6Vr1sRtUIl7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "961c1e1e-3ecd-43f6-d9f1-66faf0b15897"
      },
      "source": [
        "!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple scikit-multilearn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Collecting scikit-multilearn\n",
            "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bb/1f/e6ff649c72a1cdf2c7a1d31eb21705110ce1c5d3e7e26b2cc300e1637272/scikit_multilearn-0.2.0-py3-none-any.whl (89kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 230kB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCjjczpyRQD2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c639037-dcec-4aa7-8151-38f299bd3960"
      },
      "source": [
        "ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mBDCI_Car_2018\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptZXZ2mETtMA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f906fca-11bd-43eb-9a75-cb10b003ae50"
      },
      "source": [
        "cd BDCI_Car_2018/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/BDCI_Car_2018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egkm1wiFTvrI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "19f3f0ec-59c2-46f5-8db1-b29ddea4ab88"
      },
      "source": [
        "ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \u001b[0m\u001b[01;34mattribute_level\u001b[0m/\n",
            "'【BDCI 2018】+汽车行业用户观点主题及情感识别+Just a test+答辩PPT.pdf'\n",
            " \u001b[01;34mbert\u001b[0m/\n",
            " \u001b[01;34mdata\u001b[0m/\n",
            " \u001b[01;34mdataset\u001b[0m/\n",
            " \u001b[01;34membedding\u001b[0m/\n",
            " \u001b[01;34mpolarity_level_aspect\u001b[0m/\n",
            " ReadMe.md\n",
            " slides.pdf\n",
            " \u001b[01;34mutils\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LIw0MjxTwJN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2e8461b-ffe8-4cec-d91c-38c9dca3b2b6"
      },
      "source": [
        "cd attribute_level/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/BDCI_Car_2018/attribute_level\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLwy05z6TzfL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b878ad50-0e0b-4e18-9886-e7004f9b6dec"
      },
      "source": [
        "ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_helper.py  prepare_w2v.py           train2.py        utils.py\n",
            "Data.py         prepare_w2v_with_UNK.py  train.py         vocabulary2.pkl\n",
            "evaluate.py     \u001b[0m\u001b[01;34m__pycache__\u001b[0m/             train_single.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRP9UP-saqEM",
        "colab_type": "text"
      },
      "source": [
        "python attribute.py --mode 2 --test_dir cp_CNN_0#cp_CNN_ft2#cp_CNN_2#cp_CNN_tc#cp_AttA3_0#cp_AttA3_ft2#cp_AttA3_2#cp_AttA3_tc#cp_Bert --saved 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC5Hshj7cUf1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e02ece44-e1ee-495d-c897-721ab26a6e40"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/BDCI_Car_2018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-BkD45BmziQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaESLxV6waFg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "451e656f-45a0-4165-dfb9-c2c5e3d3aabc"
      },
      "source": [
        "filename = \"./data/train.txt\"\n",
        "fo = codecs.open(filename, encoding='utf-8')\n",
        "fo.readline()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'因为 森林 人 即将 换代 ， 这套 系统 没 必要 装 在 一 款 即将 换代 的 车型 上 ， 因为 肯定 会 影响 价格 。\\t价格#0\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVTld4nBkNZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_attr_data(filename):\n",
        "    fo = codecs.open(filename, encoding='utf-8')\n",
        "    test_text = []\n",
        "    labels = []\n",
        "    for line in fo:\n",
        "        splits = line.strip('\\n').split('\\t')\n",
        "        # text = text.lower()\n",
        "        text = splits[0]\n",
        "        text = text.strip().split(' ')\n",
        "        test_text.append(text)\n",
        "        label = []\n",
        "        for pair in splits[1:]:\n",
        "            aspect = pair.split('#')[0]\n",
        "            label.append(aspect)\n",
        "        labels.append(label)\n",
        "\n",
        "    return test_text, labels\n",
        "\n",
        "def split_dev(train_texts, train_labels, folds=5):\n",
        "    length = len(train_texts)\n",
        "    np.random.seed(1024)\n",
        "    index_list = np.random.permutation(length).tolist()\n",
        "    # print(index_list)\n",
        "\n",
        "    train_lines = [train_texts[i] for i in index_list[0:length - length // folds]]\n",
        "    test_lines = [train_texts[i] for i in index_list[length - length // folds:]]\n",
        "    train_y = [train_labels[i] for i in index_list[0:length-length//folds]]\n",
        "    test_y = [train_labels[i] for i in index_list[length - length // folds:]]\n",
        "    return train_lines, train_y, test_lines, test_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnxmeduEZ_Uq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "d19c2a61-05a1-4557-ba77-49ac08dc2eb2"
      },
      "source": [
        "f_train = \"./data/train.txt\"\n",
        "f_w2v = \"./embedding/embedding_all_fasttext2_300.txt\"\n",
        "f_dict = \"./dataset/attribute.json\"\n",
        "print(f_w2v)\n",
        "train_texts, train_labels = load_attr_data(filename=f_train)\n",
        "train_texts, train_labels, test_texts, test_labels = split_dev(train_texts, train_labels)\n",
        "print(len(train_texts))\n",
        "print(len(test_labels))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./embedding/embedding_all_fasttext2_300.txt\n",
            "8523\n",
            "2130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSYjeAcNldFV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf7290f7-b728-40bd-d391-b4458897ddec"
      },
      "source": [
        "train_labels[:5]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['动力'], ['价格'], ['配置'], ['价格'], ['配置']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3zt7_WLaAYs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "66075749-2e3b-4f66-a045-ce1f163f73af"
      },
      "source": [
        "train_texts[0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['同感',\n",
              " '，',\n",
              " '我',\n",
              " '经常',\n",
              " '开',\n",
              " 's',\n",
              " '60',\n",
              " 'L',\n",
              " '，',\n",
              " '高速',\n",
              " '很',\n",
              " '爽',\n",
              " '，',\n",
              " '动力',\n",
              " '强',\n",
              " '.',\n",
              " '市区',\n",
              " '转弯',\n",
              " '不方便',\n",
              " '，',\n",
              " '停车',\n",
              " '也',\n",
              " '麻烦',\n",
              " '，',\n",
              " '就是',\n",
              " '因为',\n",
              " '转弯',\n",
              " '半径',\n",
              " '太大']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-q4flGIaAc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "check_dir = './check_file'\n",
        "if not os.path.exists(check_dir):\n",
        "        os.mkdir(check_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adsuidIEaAgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "0fb62501-941d-4da5-d5a5-894ebbea57ef"
      },
      "source": [
        "ls"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \u001b[0m\u001b[01;34mattribute_level\u001b[0m/\n",
            "'【BDCI 2018】+汽车行业用户观点主题及情感识别+Just a test+答辩PPT.pdf'\n",
            " \u001b[01;34mbert\u001b[0m/\n",
            " \u001b[01;34mcheck_file\u001b[0m/\n",
            " \u001b[01;34mdata\u001b[0m/\n",
            " \u001b[01;34mdataset\u001b[0m/\n",
            " \u001b[01;34membedding\u001b[0m/\n",
            " \u001b[01;34mpolarity_level_aspect\u001b[0m/\n",
            " ReadMe.md\n",
            " slides.pdf\n",
            " \u001b[01;34mutils\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_UPI-pG76as",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c1833dc7-b2ba-4c9a-ee5c-b10d3095c4ce"
      },
      "source": [
        "filename = \"./embedding/embedding_all_fasttext2_300.txt\"\n",
        "f_w2v = codecs.open(filename, encoding=\"utf-8\").readlines()\n",
        "f_w2v[:3]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['15995 300\\n',\n",
              " '野外 0.0822999998927 0.0324000008404 0.291500002146 0.0645999982953 0.0720999985933 0.0452000014484 -0.111699998379 -0.158600002527 -0.269899994135 -0.127700001001 0.0322999991477 0.0222999993712 -0.116700001061 -0.234999999404 0.197500005364 0.12160000205 0.2799000144 -0.0148999998346 0.00579999992624 0.195600003004 -0.223000004888 0.117700003088 -0.269699990749 -0.0132999997586 0.10000000149 -0.0763000026345 -0.215800002217 -0.0671000033617 -0.123000003397 0.149700000882 -0.186499997973 0.227099999785 0.30189999938 0.431300014257 -0.286100000143 -0.0953999981284 -0.0463999994099 -0.303700000048 -0.250999987125 0.270799994469 -0.0649999976158 -0.0142000000924 0.0873000025749 -0.23710000515 -0.0526000000536 -0.0428999997675 -0.00089999998454 -0.11060000211 -0.0240000002086 -0.186199992895 0.297500014305 -0.13750000298 -0.0582999996841 -0.0670000016689 0.00159999995958 -0.0487000010908 0.0264999996871 -0.00419999985024 -0.0111999996006 0.00579999992624 -0.170300006866 0.0825000032783 0.0097000002861 -0.0746000036597 0.143600001931 0.206000000238 0.0333000011742 -0.220599994063 -0.0472000017762 0.419400006533 -0.238800004125 0.0592000000179 -0.070000000298 -0.278200000525 -0.102499999106 -0.0778999999166 -0.0427000001073 -0.215499997139 0.0986000001431 0.162400007248 -0.0441999994218 -0.095600001514 0.324400007725 0.174400001764 -0.0830999985337 -0.134200006723 0.261799991131 0.22879999876 0.171399995685 -0.0102000003681 -0.10909999907 0.0362000018358 0.0566000007093 0.0348999984562 0.322499990463 0.0310999993235 -0.0798000022769 -0.0640000030398 0.0165999997407 -0.0214000009 -0.0401000007987 0.426600009203 -0.0100999996066 -0.198699995875 0.0372000001371 0.108599998057 -0.0189999993891 -0.0882000029087 0.0555000007153 0.164499998093 -0.0838000029325 -0.221699997783 0.0441999994218 0.262699991465 -0.166800007224 -0.0615000016987 0.0782999992371 0.236499994993 -0.0179999992251 -0.023199999705 0.392399996519 0.4117000103 -0.126599997282 0.0526000000536 0.049699999392 -0.0520000010729 -0.153500005603 0.00730000017211 0.221900001168 -0.234400004148 -0.300999999046 -0.147599995136 -0.41400000453 0.163200005889 -0.0882999971509 -0.00190000003204 0.22990000248 -0.134200006723 0.236200004816 -0.152199998498 0.202900007367 -0.110500000417 0.135000005364 -0.00700000021607 0.323700010777 0.035300001502 0.0838000029325 0.069399997592 -0.0718000009656 -0.219500005245 0.14849999547 0.150199994445 -0.154799997807 0.216999992728 -0.28330001235 -0.212799996138 -0.195299997926 -0.275999993086 -0.0515000000596 0.111800000072 0.0399999991059 -0.15909999609 0.300799995661 -0.16210000217 0.0975999981165 0.00300000002608 -0.0472999997437 -0.00669999979436 -0.0264999996871 0.082800000906 0.148800000548 0.00669999979436 -0.116099998355 -0.0524999983609 0.00310000008903 0.0784000009298 0.147300004959 0.000600000028498 -0.119800001383 0.0225000008941 0.0758000016212 0.129099994898 -0.0217000003904 -0.0225000008941 -0.00249999994412 0.0423999987543 0.242100000381 -0.114900000393 -0.00949999969453 0.521000027657 -0.144400000572 -0.161699995399 -0.211899995804 -0.266499996185 0.0658999979496 -0.236499994993 -0.0441999994218 -0.195399999619 -0.174300000072 0.0566000007093 0.107699997723 -0.29699999094 0.0295000001788 -0.213899999857 -0.0878999978304 -0.0728999972343 0.137400001287 0.322200000286 0.192499995232 0.081200003624 -0.199900001287 0.0716999992728 -0.18559999764 0.0137000000104 0.209700003266 -0.102600000799 0.216499999166 -0.105700001121 -0.0359000004828 0.247199997306 0.14390000701 0.122100003064 -0.172900006175 0.0722000002861 0.0348999984562 -0.104800000787 -0.0826999992132 -0.200599998236 0.14319999516 0.301400005817 0.404100000858 0.768899977207 0.0653999969363 0.0483000017703 -0.246299996972 -0.022199999541 -0.0601000003517 -0.0232999995351 0.105800002813 0.0322999991477 0.231399998069 -0.00769999995828 -0.143700003624 -0.054200001061 -0.0491000004113 -0.326599985361 -0.216499999166 -0.341500014067 -0.0209999997169 -0.281399995089 0.0974000021815 0.524900019169 0.209700003266 -0.107100002468 0.0878999978304 -0.120099999011 0.020300000906 0.0667999982834 0.0778999999166 -0.175699993968 0.27270001173 0.0129000004381 0.0601000003517 -0.061700001359 -0.0252999998629 0.334500014782 0.221499994397 0.302500009537 -0.0366999991238 -0.188299998641 -0.0200999993831 0.229800000787 -0.0173000004143 -0.141000002623 0.0511999987066 -0.0810000002384 -0.0164000000805 -0.387699991465 0.0197999998927 -0.0447999984026 -0.53869998455 -0.0218000002205 0.364300012589 0.0989999994636 -0.253699988127 0.16740000248 0.262699991465 0.00760000012815 0.194100007415 -0.222900003195 -0.0294000003487 -0.231999993324 -0.0815000012517 0.0639000013471 0.287299990654 0.17919999361 0.128499999642 0.346199989319 0.156299993396 0.0142000000924\\n',\n",
              " '一体机 0.0962999984622 0.0244999993593 0.300599992275 -0.0439999997616 -0.0273000001907 0.15000000596 -0.075900003314 -0.0337000004947 -0.0860999971628 -0.216900005937 0.0131000000983 0.0590999983251 -0.0900999978185 -0.0131000000983 -0.0786999985576 -0.0992000028491 -0.077500000596 -0.0377000011504 -0.0377000011504 -0.0790000036359 0.0177999995649 -0.00839999970049 0.062199998647 -0.047800000757 0.0109999999404 -0.127700001001 0.101199999452 -0.0447999984026 -0.040600001812 -0.0595000013709 0.102200001478 -0.0860999971628 -0.115199998021 0.00810000021011 0.00460000010207 0.0105999996886 0.0723000019789 0.104000002146 0.0135000003502 0.135800004005 0.0612000003457 -0.00820000004023 0.0852999985218 -0.213200002909 0.12800000608 0.135900005698 0.304800003767 0.118600003421 0.116499997675 -0.0604000017047 -0.0351000018418 -0.118000000715 0.0291000008583 0.108199998736 -0.101800002158 -0.10000000149 0.101000003517 0.0524999983609 0.00659999996424 -0.0715999975801 0.054999999702 0.126000002027 0.0222999993712 -0.0945999994874 -0.07689999789 0.0987000018358 -0.0181000009179 0.00870000012219 0.0109999999404 -0.0839999988675 0.0566999986768 0.133100003004 -0.0997999981046 -0.116400003433 -0.104099996388 -0.142599999905 -0.0364000014961 0.0155999995768 0.0386999994516 -0.0737999975681 0.0511999987066 0.0784000009298 0.0406999997795 -0.0766000002623 0.043299999088 0.0370999984443 -0.0460000000894 0.0165999997407 -0.0597000010312 0.0546000003815 0.0542999990284 0.177699998021 0.163100004196 -0.0288999993354 0.182600006461 -0.00540000014007 -0.0900000035763 0.0331999994814 -0.0854000002146 0.0456999987364 -0.196999996901 0.105200000107 0.0741999968886 -0.0406999997795 -0.0890000015497 -0.0294000003487 0.0445999987423 0.0342999994755 -0.075900003314 -0.0705000013113 0.0384999997914 -0.135700002313 0.0780000016093 -0.00609999988228 0.0320999994874 -0.0093999998644 0.0522999987006 0.172099992633 0.0237000007182 -0.0443999990821 0.162900000811 0.140200003982 0.0326000005007 0.0115999998525 -0.0662999972701 0.213400006294 0.0987000018358 0.159999996424 0.0926000028849 0.246800005436 -0.310000002384 -0.0109999999404 -0.0821999981999 0.000699999975041 0.152600005269 -0.00449999980628 -0.0131999999285 0.0417999997735 0.0588000006974 -0.0131999999285 0.0395000018179 0.105999998748 0.0267999991775 -0.117899999022 0.0859000012279 0.0285000000149 0.0960000008345 0.0856999978423 0.0590000003576 0.021099999547 -0.0471000000834 -0.124200001359 0.207000002265 -0.00430000014603 0.0187999997288 -0.0821999981999 -0.061700001359 -0.0636000037193 0.062199998647 0.146300002933 -0.0904000028968 -0.00179999996908 0.00410000002012 0.0930999964476 -0.0575999990106 -0.120099999011 -0.173199996352 -0.048599999398 0.0149999996647 -0.113099999726 0.0476000010967 0.122199997306 0.0188999995589 -0.130600005388 -0.0233999993652 0.0104000000283 0.0806000009179 -0.0738999992609 0.102700002491 0.0590000003576 -0.00680000009015 -0.0388999991119 -0.0706999972463 0.127000004053 -0.0702999979258 -0.148900002241 0.122800000012 -0.0679000020027 0.0406999997795 0.0883999988437 -0.0483999997377 0.0247000008821 0.00380000006407 0.0781000033021 0.0480000004172 0.0529999993742 0.017100000754 0.111900001764 -0.178100004792 -0.106299996376 0.128800004721 0.0471000000834 -0.0251000002027 -0.0262000001967 0.123899996281 -0.0397999994457 0.124300003052 0.0568000003695 -0.140100002289 -0.0340000018477 -0.153899997473 0.0159000009298 0.155799999833 0.0923999994993 0.0395999997854 -0.0414999984205 0.0967999994755 0.0555999986827 -0.0439999997616 0.0348999984562 0.0172000005841 0.0511999987066 -0.0750999972224 0.0179999992251 0.119900003076 0.0460000000894 0.0960000008345 -0.00529999984428 -0.15569999814 -0.292899996042 -0.0366000011563 0.547200024128 -0.0430000014603 0.0131999999285 -0.0965000018477 -0.0535000003874 -0.00279999990016 0.227599993348 0.110200002789 0.0529999993742 -0.132799997926 -0.0548000000417 -0.144800007343 0.115199998021 -0.0195000004023 -0.0465000011027 0.138300001621 0.0851000025868 -0.034200001508 0.056899998337 0.00609999988228 -0.0949999988079 -0.102200001478 0.0658999979496 0.0185000002384 0.0326999984682 0.083400003612 0.172000005841 -0.249799996614 -0.084399998188 0.0381000004709 0.00139999995008 -0.0469999983907 -0.0667999982834 -0.0619000010192 -0.0456999987364 0.00980000011623 -0.0886999964714 -0.0226000007242 -0.0441999994218 -0.0612000003457 0.106299996376 0.00499999988824 -0.0142999999225 -0.056899998337 0.0844999998808 0.00829999987036 -0.054699998349 -0.142100006342 -0.0230000000447 -0.217600002885 -0.188099995255 0.108599998057 -0.0373000018299 0.145899996161 -0.0885000005364 0.0414999984205 0.118699997663 -0.0408000014722 -0.14620000124 -0.0156999994069 -0.0306000001729 -0.162799999118 -0.0502999983728 -0.0795999988914 0.0515000000596 -0.100199997425 0.0126000000164 0.169900000095 0.101499997079\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2no9gYbY-4Qb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee3b5bd7-c00d-407d-a44b-dfeaccdcd360"
      },
      "source": [
        "len(ｆ_w2v[1].strip('\\n').split(' '))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "301"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ35Fxcy1RSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_w2v(filename):\n",
        "    f_w2v = codecs.open(filename, encoding=\"utf-8\").readlines()\n",
        "    # embedding_all_fasttext2_300.txt 第一行有两个以空白符连接的数字，一个是词向量个数，第二个是词向量维度\n",
        "    vocab_size = int(f_w2v[0].split()[0])\n",
        "    embed_size = int(f_w2v[0].split()[1])\n",
        "    # print(\"Vocab size: %d\" % vocab_size)\n",
        "    # print(\"Embed size: %d\" % embed_size)\n",
        "    word2index = dict()\n",
        "    W = np.zeros(shape=(vocab_size, embed_size), dtype='float32')\n",
        "    for i in range(1, vocab_size+1):\n",
        "        line = f_w2v[i].strip('\\r\\n').split(' ')\n",
        "        w = ''.join(line[0:len(line)-embed_size])\n",
        "        vec = line[len(line)-embed_size:]\n",
        "        vec = [float(v) for v in vec]\n",
        "        # print(embed_size)\n",
        "        # print(len(vec))\n",
        "        # print(w)\n",
        "        assert len(vec) == embed_size\n",
        "        word2index[w] = i - 1\n",
        "        W[i-1] = vec\n",
        "    # print(len(W))\n",
        "    # print(W[0])\n",
        "    return W, word2index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHVOqTYTaAnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "f_w2v = \"./embedding/embedding_all_fasttext2_300.txt\"\n",
        "W, word2index2 = load_w2v(f_w2v)\n",
        "word2index = pickle.load(open(\"./data/vocabulary.pkl\", 'rb'))\n",
        "assert word2index == word2index2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiRp1QhwaAtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "def parse_json(filename):\n",
        "    entity_list = []\n",
        "    df = pd.read_json(filename, encoding='utf-8')\n",
        "    df = df['value']\n",
        "    for d in df:\n",
        "        entity_list.append(d['attribute2'])\n",
        "    # entity_list.append('')\n",
        "    entity_dict = {k: v for v, k in enumerate(entity_list)}\n",
        "    return entity_list, entity_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEnzmfgYaA0S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e5a019a-a37a-4287-f3d8-693a7516dde0"
      },
      "source": [
        "attr_list, attr_dict = parse_json(f_dict)\n",
        "print(list(attr_dict.keys()))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['动力', '价格', '内饰', '配置', '安全性', '外观', '操控', '油耗', '空间', '舒适性']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I18-AgRLaA4B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "248fa9ff-fbe8-4b79-a89e-493a280651b1"
      },
      "source": [
        "attr_dict"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'价格': 1,\n",
              " '内饰': 2,\n",
              " '动力': 0,\n",
              " '外观': 5,\n",
              " '安全性': 4,\n",
              " '操控': 6,\n",
              " '油耗': 7,\n",
              " '空间': 8,\n",
              " '舒适性': 9,\n",
              " '配置': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv2o9EL_aA_A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d70db028-2528-4014-9087-a87b08710e86"
      },
      "source": [
        "print(attr_list)\n",
        "print(attr_dict)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['动力', '价格', '内饰', '配置', '安全性', '外观', '操控', '油耗', '空间', '舒适性']\n",
            "{'动力': 0, '价格': 1, '内饰': 2, '配置': 3, '安全性': 4, '外观': 5, '操控': 6, '油耗': 7, '空间': 8, '舒适性': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ9iTmgOcD71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class args:\n",
        "  model = 'CNN'\n",
        "  n_hidden = 128\n",
        "  use_elmo = 0\n",
        "  EPOCHS = 5\n",
        "  lr = 0.2\n",
        "  optimizer = 'Adam'\n",
        "  freeze = True\n",
        "  check_dir = './check_file'\n",
        "  save = 1\n",
        "  dropout = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyNPZBicRoZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "class WordRep(nn.Module):\n",
        "    def __init__(self, vocab_size, word_embed_dim, char_size, args):\n",
        "        super(WordRep, self).__init__()\n",
        "        # self.use_char = args.use_char\n",
        "        self.use_elmo = args.use_elmo\n",
        "        # self.elmo_mode = args.elmo_mode\n",
        "        # self.elmo_mode2 = args.elmo_mode2\n",
        "        # self.projected = args.projected\n",
        "        # self.char_embed_dim = args.char_embed_dim\n",
        "        self.word_embed = nn.Embedding(vocab_size, word_embed_dim)\n",
        "        # if self.use_elmo:\n",
        "        #     self.elmo_weights = nn.Linear(3, 1)\n",
        "        #     self.elmo_proj = nn.Linear(1024, word_embed_dim)\n",
        "        # if self.use_char:\n",
        "        #     self.char_embed = nn.Embedding(char_size, self.char_embed_dim)\n",
        "        #     self.char_lstm = nn.LSTM(self.char_embed_dim, self.char_embed_dim//2, num_layers=1, bidirectional=True)\n",
        "\n",
        "    def forward(self, input_tensors):\n",
        "        sentence = input_tensors[0]\n",
        "        elmo_tensor = input_tensors[1]\n",
        "        char_seq = None\n",
        "        char_seq_len = None\n",
        "        char_seq_recover = None\n",
        "        words_embeds = self.word_embed(sentence)\n",
        "        if self.use_elmo == 1:\n",
        "            elmo_tensor = elmo_tensor.view(elmo_tensor.size()[0], 1, -1)\n",
        "            words_embeds = torch.cat((words_embeds, elmo_tensor), dim=-1)\n",
        "        elif self.use_elmo == 2:\n",
        "            elmo_tensor = elmo_tensor.view(elmo_tensor.size()[0], 1, -1)\n",
        "            words_embeds = elmo_tensor\n",
        "        # if self.use_elmo:\n",
        "        #     if self.elmo_mode == 2:\n",
        "        #         elmo_tensor = elmo_tensor[-1]\n",
        "        #     elif self.elmo_mode == 3:\n",
        "        #         elmo_tensor = elmo_tensor[1]\n",
        "        #     elif self.elmo_mode == 4:\n",
        "        #         elmo_tensor = elmo_tensor[0]\n",
        "        #     elif self.elmo_mode == 6:\n",
        "        #         attn_weights = F.softmax(self.elmo_weights.weight, dim=-1)\n",
        "        #         elmo_tensor = torch.matmul(attn_weights, elmo_tensor.t())\n",
        "        #     else:\n",
        "        #         elmo_tensor = elmo_tensor.mean(dim=0)\n",
        "        #     if not self.projected:\n",
        "        #         projected = elmo_tensor\n",
        "        #     else:\n",
        "        #         projected = self.elmo_proj(elmo_tensor)\n",
        "        #     # print(words_embeds.size())\n",
        "        #     # exit(-1)\n",
        "        #     projected = projected.view(projected.size()[0], 1, -1)\n",
        "        #     if self.elmo_mode2 == 1:\n",
        "        #         words_embeds = words_embeds + projected\n",
        "        #     elif self.elmo_mode2 == 2:\n",
        "        #         words_embeds = words_embeds\n",
        "        #     elif self.elmo_mode2 == 3:\n",
        "        #         words_embeds = torch.cat((words_embeds, projected), dim=-1)\n",
        "        #     else:\n",
        "        #         words_embeds = projected\n",
        "        # if self.use_char:\n",
        "        #     char_embeds = self.char_embed(char_seq)\n",
        "        #     pack_seq = pack_padded_sequence(char_embeds, char_seq_len, True)\n",
        "        #     char_rnn_out, char_hidden = self.char_lstm(pack_seq)\n",
        "        #     last_hidden = char_hidden[0].view(sentence.size()[0], 1, -1)\n",
        "        #     # print(words_embeds)\n",
        "        #     # print(last_hidden)\n",
        "        #     words_embeds = torch.cat((words_embeds, last_hidden), -1)\n",
        "        return words_embeds\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, word_embed_dim, output_size, vocab_size, args=None):\n",
        "        super(LSTM, self).__init__()\n",
        "        print(\"LSTM\")\n",
        "        self.input_size = word_embed_dim\n",
        "        # if args.elmo_mode2 == 3 and args.projected and args.use_elmo:\n",
        "        #     self.input_size += word_embed_dim\n",
        "        # if args.elmo_mode2 == 0 and not args.projected and args.use_elmo:\n",
        "        #     self.input_size = 1024\n",
        "        # if args.elmo_mode2 == 3 and not args.projected and args.use_elmo:\n",
        "        #     self.input_size += 1024\n",
        "        self.hidden_size = args.n_hidden\n",
        "        self.output_size = output_size\n",
        "        self.max_length = 1\n",
        "        self.word_rep = WordRep(vocab_size, word_embed_dim, None, args)\n",
        "        self.rnn = nn.LSTM(self.input_size, self.hidden_size, num_layers=1, bidirectional=True)\n",
        "\n",
        "        self.decoderP = nn.Linear(self.hidden_size*2, self.output_size)\n",
        "        self.dropout = nn.Dropout(0.0)\n",
        "\n",
        "    def forward(self, input_tensors):\n",
        "        # print(sentence)\n",
        "        sentence = self.word_rep(input_tensors)\n",
        "        output, (hidden, _) = self.rnn(sentence)\n",
        "        hidden = hidden.view(1, -1)\n",
        "        decodedP = self.decoderP(hidden).view(1, -1)\n",
        "\n",
        "        # outputP = F.softmax(decodedP, dim=-1)\n",
        "        outputP = decodedP\n",
        "        # print(outputP.size())\n",
        "        return outputP\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, word_embed_dim, output_size, vocab_size, args=None, max_length=20):\n",
        "        super(CNN, self).__init__()\n",
        "        print(\"CNN\")\n",
        "        self.input_size = word_embed_dim if (args.use_elmo == 0) else (\n",
        "            word_embed_dim + 1024 if args.use_elmo == 1 else 1024)\n",
        "        # if args.elmo_mode2 == 3 and args.projected and args.use_elmo:\n",
        "        #     self.input_size += word_embed_dim\n",
        "        # if args.elmo_mode2 == 0 and not args.projected and args.use_elmo:\n",
        "        #     self.input_size = 1024\n",
        "        # if args.elmo_mode2 == 3 and not args.projected and args.use_elmo:\n",
        "        #     self.input_size += 1024\n",
        "        self.hidden_size = args.n_hidden\n",
        "        self.output_size = output_size\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.word_rep = WordRep(vocab_size, word_embed_dim, None, args)\n",
        "        self.filter_size = [1, 2, 3, 4]\n",
        "        self.map_size = 300\n",
        "\n",
        "        self.convs1 = nn.ModuleList([nn.Conv1d(self.input_size, self.map_size, K) for K in self.filter_size])\n",
        "\n",
        "        # self.pool1 = nn.MaxPool2d((max_length - self.filter_size[0] + 1, 1))\n",
        "        # self.pool2 = nn.MaxPool2d((max_length - self.filter_size[1] + 1, 1))\n",
        "        # self.pool3 = nn.MaxPool2d((max_length - self.filter_size[2] + 1, 1))\n",
        "\n",
        "        # self.decoder = nn.Linear(self.map_size*3, output_size)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(self.map_size*len(self.filter_size), self.hidden_size),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(self.hidden_size, self.output_size)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(args.dropout)\n",
        "\n",
        "        # self.pad = torch.nn.ConstantPad3d((0, 0, 0, 0, 0, ))\n",
        "        # self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, input_tensors):\n",
        "        feature = self.word_rep(input_tensors)\n",
        "        # input = F.pad(input, (0, 0, 0, 0, 0, self.max_length-input.size()[0])).view(1, self.max_length, -1)\n",
        "        feature = feature.view(1, feature.size()[0], -1)\n",
        "        feature = self.dropout(feature)\n",
        "\n",
        "        x = [F.tanh(conv(feature.transpose(1, 2))) for conv in self.convs1]\n",
        "\n",
        "        x0 = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]\n",
        "        x0 = [i.view(i.size(0), -1) for i in x0]\n",
        "        x0 = torch.cat(x0, 1)\n",
        "\n",
        "        # c = self.dropout(c)\n",
        "        decoded = self.decoder(x0)\n",
        "        # decoded = self.dropout(decoded)\n",
        "        # ouput = self.softmax(decoded)\n",
        "        output = decoded\n",
        "        output = F.sigmoid(output.view(1, -1))\n",
        "        return output\n",
        "\n",
        "    def optimize_step(self, input_tensors, category_tensor, optimizer):\n",
        "        self.zero_grad()\n",
        "        self.train()\n",
        "        output = self.forward(input_tensors)\n",
        "        # print(output)\n",
        "        # print(category_tensor)\n",
        "\n",
        "        # loss = F.multilabel_soft_margin_loss(output, category_tensor.float())\n",
        "        loss = F.binary_cross_entropy(output, category_tensor.float())\n",
        "        # loss = customized_loss2(output, category_tensor.float())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        return loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYFqsex0dOYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Data:\n",
        "    def __init__(self, train_raw_data, word2index, attr_dict=None, args=None):\n",
        "        self.sentences = None\n",
        "        self.targets = None\n",
        "        self.labels = None\n",
        "        self.chars = None\n",
        "        self.pos = None\n",
        "        self.char_lens = None\n",
        "        self.char_recover = None\n",
        "        self.features = None\n",
        "\n",
        "        train_texts = train_raw_data[0]\n",
        "        train_labels = train_raw_data[1]\n",
        "\n",
        "        self.sentences = [self.to_tensor(s, word2index) for s in train_texts]  # [L*1*dim]\n",
        "        if train_labels is not None:\n",
        "            self.labels = [self.label2tensor(y, attr_dict) for y in train_labels]\n",
        "\n",
        "    def get(self, index, cuda_flag):\n",
        "        line_tensor = self.sentences[index]\n",
        "        if self.labels is None:\n",
        "            category_tensor = None\n",
        "        else:\n",
        "            category_tensor = self.labels[index]\n",
        "            if cuda_flag:\n",
        "                category_tensor = category_tensor.cuda()\n",
        "        if cuda_flag:\n",
        "            line_tensor = line_tensor.cuda()\n",
        "        if self.features is None:\n",
        "            elmo_tensor = None\n",
        "        else:\n",
        "            elmo_tensor = self.features[index]\n",
        "            if cuda_flag:\n",
        "                elmo_tensor = elmo_tensor.cuda()\n",
        "\n",
        "        return (line_tensor, elmo_tensor), category_tensor\n",
        "\n",
        "    def add_feature(self, features):\n",
        "        self.features = features\n",
        "\n",
        "    def get_input(self, index, cuda_flag):\n",
        "        pass\n",
        "\n",
        "    def to_tensor(self, text, word2id):\n",
        "        index_list = []\n",
        "        # print(text)\n",
        "        for w in text:\n",
        "            w = w\n",
        "            if w in word2id:\n",
        "                index_list.append(word2id[w])\n",
        "            else:\n",
        "                # print( w == '')\n",
        "                # if ' ' not in w:\n",
        "                print(w)\n",
        "                print(\"2id error\")\n",
        "                w = 'UNK'\n",
        "                # print(w)\n",
        "                index_list.append(word2id[w])\n",
        "        tensor = torch.from_numpy(np.asarray(index_list))\n",
        "        tensor = tensor.view(tensor.size()[0], -1).long()\n",
        "        return tensor\n",
        "\n",
        "    def label2tensor(self, labels, attrDict):\n",
        "        tensor = [0 for i in range(len(attrDict))]\n",
        "        for l in labels:\n",
        "            if l in attrDict:\n",
        "                tensor[attrDict[l]] = 1\n",
        "            # else:\n",
        "            #     print(w)\n",
        "            #     print(\"2id error\")\n",
        "            #     w = 'UNK'\n",
        "            #     index_list.append(word2id[w])\n",
        "        tensor = torch.from_numpy(np.asarray(tensor))\n",
        "        tensor = tensor.view(1, tensor.size()[0]).long()\n",
        "        return tensor\n",
        "\n",
        "    def generate_char_tensor(self, text, char2id):\n",
        "        char_len_list = list(map(len, text))\n",
        "        words_length = len(text)\n",
        "        max_seq_len = max(char_len_list)\n",
        "        char_seq_tensor = torch.zeros((words_length, max_seq_len)).long()\n",
        "        char_seq_lengths = torch.LongTensor(char_len_list)\n",
        "        for idx, (word, charlen) in enumerate(zip(text, char_seq_lengths)):\n",
        "            c_i_list = []\n",
        "            for c in word:\n",
        "                if c in char2id:\n",
        "                    c_i_list.append(char2id[c])\n",
        "                else:\n",
        "                    print(\"char2id error\")\n",
        "            # print len(word), wordlen\n",
        "            char_seq_tensor[idx, :charlen] = torch.LongTensor(c_i_list)\n",
        "        char_seq_lengths, char_perm_idx = char_seq_lengths.sort(0, descending=True)\n",
        "        char_seq_tensor = char_seq_tensor[char_perm_idx]\n",
        "        _, char_seq_recover = char_perm_idx.sort(0, descending=False)\n",
        "        return char_seq_tensor, char_seq_lengths, char_seq_recover"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klnt_R8TvDEs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "394f949e-68ca-44bb-889a-cd830d8f9a97"
      },
      "source": [
        "cuda_flag = True and torch.cuda.is_available()\n",
        "cuda_flag"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJn8NtN92Qh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
        "\n",
        "\n",
        "def score_list(predicted, golden):\n",
        "    assert len(predicted) == len(golden)\n",
        "    correct = 0\n",
        "    for p, g in zip(predicted, golden):\n",
        "        # print(p)\n",
        "        # print(g)\n",
        "        # print(g[0].tolist())\n",
        "        # exit(-1)\n",
        "        if p == g:\n",
        "            correct += 1\n",
        "    acc = correct/len(golden)\n",
        "\n",
        "    predicted_all = [l for p in predicted for l in p]\n",
        "    golden_all = [l for g in golden for l in g]\n",
        "    precision = precision_score(golden_all, predicted_all)\n",
        "    recall = recall_score(golden_all, predicted_all)\n",
        "    f1 = f1_score(golden_all, predicted_all)\n",
        "    f12 = f1_score(predicted_all, golden_all)\n",
        "\n",
        "    return precision, recall, f1, acc\n",
        "\n",
        "\n",
        "def score(predicted, golden):\n",
        "    assert len(predicted) == len(golden)\n",
        "    correct = 0\n",
        "    for p, g in zip(predicted, golden):\n",
        "        # print(p)\n",
        "        # print(g)\n",
        "        # print(g[0].tolist())\n",
        "        # exit(-1)\n",
        "        if p == g[0].tolist():\n",
        "            correct += 1\n",
        "    acc = correct/len(golden)\n",
        "\n",
        "    predicted_all = [l for p in predicted for l in p]\n",
        "    golden_all = [l for g in golden for l in g[0].tolist()]\n",
        "    precision = precision_score(golden_all, predicted_all)\n",
        "    recall = recall_score(golden_all, predicted_all)\n",
        "    f1 = f1_score(golden_all, predicted_all)\n",
        "    f12 = f1_score(predicted_all, golden_all)\n",
        "\n",
        "    return precision, recall, f1, acc\n",
        "\n",
        "\n",
        "def label_analysis(predicted, golden):\n",
        "    assert len(predicted) == len(golden)\n",
        "    golden = np.asarray([g[0].tolist() for g in golden])\n",
        "    predicted = np.asarray(predicted)\n",
        "    rslt = []\n",
        "    for i in range(golden.shape[1]):\n",
        "        p = precision_score(golden[:, i], predicted[:, i])\n",
        "        r = recall_score(golden[:, i], predicted[:, i])\n",
        "        f = f1_score(golden[:, i], predicted[:, i])\n",
        "        rate = sum(golden[:, i]) / golden.shape[0]\n",
        "        rslt.append([p, r, f, rate])\n",
        "    return rslt\n",
        "\n",
        "\n",
        "def score2(predicted, golden):\n",
        "    # print(len(predicted))\n",
        "    # print(len(golden))\n",
        "    assert len(predicted) == len(golden)\n",
        "    correct = 0\n",
        "    for p, g in zip(predicted, golden):\n",
        "        if p == g[0].tolist():\n",
        "            correct += 1\n",
        "    acc = correct/len(golden)\n",
        "\n",
        "    predicted_all = [p[0].tolist() for p in predicted]\n",
        "    # print(predicted_all)\n",
        "    golden_all = [g[0].tolist() for g in golden]\n",
        "    # print(golden_all)\n",
        "    p, r, f, _ = precision_recall_fscore_support(golden_all, predicted_all, average='micro')\n",
        "\n",
        "    return p, r, f, acc\n",
        "\n",
        "\n",
        "def label_analysis2(predicted, golden, label_num):\n",
        "    assert len(predicted) == len(golden)\n",
        "\n",
        "    rslt = []\n",
        "\n",
        "    predicted_all = [p for p in predicted]\n",
        "    golden_all = [g[0].tolist() for g in golden]\n",
        "    P, R, F, Support = precision_recall_fscore_support(golden_all, predicted_all, labels=[i for i in range(label_num)])\n",
        "    for p, r, f, s in zip(P, R, F, Support):\n",
        "        rslt.append([p, r, f, s])\n",
        "    # print(len(rslt))\n",
        "    return rslt\n",
        "\n",
        "def score_aspect(predict_list, true_list):\n",
        "    correct = 0\n",
        "    predicted = 0\n",
        "    relevant = 0\n",
        "\n",
        "    i = 0\n",
        "    j = 0\n",
        "    pairs = []\n",
        "    while i < len(true_list):\n",
        "        true_seq = true_list[i]\n",
        "        predict = predict_list[i]\n",
        "\n",
        "        for num in range(len(true_seq)):\n",
        "            if true_seq[num] == 0:\n",
        "                if num < len(true_seq) - 1:\n",
        "                    # if true_seq[num + 1] == '0' or true_seq[num + 1] == '1':\n",
        "                    if true_seq[num + 1] != 1:\n",
        "                        # if predict[num] == '1':\n",
        "                        if predict[num] == 0 and predict[num + 1] != 1:\n",
        "                            # if predict[num] == '1' and predict[num + 1] != '1':\n",
        "                            correct += 1\n",
        "                            # predicted += 1\n",
        "                            relevant += 1\n",
        "                        else:\n",
        "                            relevant += 1\n",
        "\n",
        "                    else:\n",
        "                        if predict[num] == 0:\n",
        "                            for j in range(num + 1, len(true_seq)):\n",
        "                                if true_seq[j] == 1:\n",
        "                                    if predict[j] == 1 and j < len(predict) - 1:\n",
        "                                        # if predict[j] == '1' and j < len(predict) - 1:\n",
        "                                        continue\n",
        "                                    elif predict[j] == 1 and j == len(predict) - 1:\n",
        "                                        # elif predict[j] == '1' and j == len(predict) - 1:\n",
        "                                        correct += 1\n",
        "                                        relevant += 1\n",
        "\n",
        "                                    else:\n",
        "                                        relevant += 1\n",
        "                                        break\n",
        "\n",
        "                                else:\n",
        "                                    if predict[j] != 1:\n",
        "                                        # if predict[j] != '1':\n",
        "                                        correct += 1\n",
        "                                        # predicted += 1\n",
        "                                        relevant += 1\n",
        "                                        break\n",
        "\n",
        "\n",
        "                        else:\n",
        "                            relevant += 1\n",
        "\n",
        "                else:\n",
        "                    if predict[num] == 0:\n",
        "                        correct += 1\n",
        "                        # predicted += 1\n",
        "                        relevant += 1\n",
        "                    else:\n",
        "                        relevant += 1\n",
        "\n",
        "        for num in range(len(predict)):\n",
        "            if predict[num] == 0:\n",
        "                predicted += 1\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    precision = float(correct) / (predicted + 1e-6)\n",
        "    recall = float(correct) / (relevant + 1e-6)\n",
        "    f1 = 2 * precision * recall / (precision + recall + 1e-6)\n",
        "\n",
        "    return precision, recall, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64F-BcBnpS_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cuda_flag = True and torch.cuda.is_available()\n",
        "def train(rnn, train_data, dev_data, test_data, attr_dict, W, args):\n",
        "    # Train:\n",
        "    # HyperParameter\n",
        "    n_epochs = args.EPOCHS\n",
        "    learning_rate = args.lr  # If you set this too high, it might explode. If too low, it might not learn\n",
        "    if W is not None:\n",
        "        W = torch.from_numpy(W)\n",
        "        rnn.word_rep.word_embed.weight = nn.Parameter(W)\n",
        "    # if W is not None:\n",
        "    #     rnn.word_rep.word_embed.weight = nn.Parameter(W)\n",
        "    print(\"CUDA: \" +str(cuda_flag))\n",
        "    if cuda_flag:\n",
        "        rnn = rnn.cuda()\n",
        "    # rnn = TextCNN(300, output_size, max_length)\n",
        "    if args.optimizer == \"SGD\":\n",
        "        optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)\n",
        "    if args.optimizer == \"Adam\":\n",
        "        optimizer = torch.optim.Adam(rnn.parameters())\n",
        "    if args.optimizer == \"Adadelta\":\n",
        "        optimizer = torch.optim.Adadelta(rnn.parameters())\n",
        "    if args.freeze:\n",
        "        for param in rnn.word_rep.word_embed.parameters():\n",
        "            param.requires_grad = False\n",
        "    print_every = 100\n",
        "    plot_every = 30\n",
        "    # Keep track of losses for plotting\n",
        "    current_loss = []\n",
        "    all_losses = []\n",
        "    test_acc = []\n",
        "    acc_index = 0\n",
        "    es_len = 0\n",
        "\n",
        "    start = time.time()\n",
        "    max_acc = 0\n",
        "\n",
        "    # scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "    np.random.seed([3, 1415])\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        iterations = 0\n",
        "        loss_sum = 0\n",
        "        # scheduler.step()\n",
        "        index_list = np.arange(len(train_data.sentences))\n",
        "        np.random.shuffle(index_list)\n",
        "        # print(index_list)\n",
        "        for index in index_list:\n",
        "            iterations += 1\n",
        "            input_tensors, category_tensor = train_data.get(index, cuda_flag)\n",
        "            loss = rnn.optimize_step(input_tensors, category_tensor, optimizer)\n",
        "            # print(loss)\n",
        "            current_loss.append(loss)\n",
        "            loss_sum += loss\n",
        "\n",
        "            # Add current loss avg to list of losses\n",
        "            if (index+1) % plot_every == 0:\n",
        "                # print(batch_epoch)\n",
        "                all_losses.append(sum(current_loss) / len(current_loss))\n",
        "                current_loss = []\n",
        "\n",
        "            if iterations % (len(index_list) //1) == 0:\n",
        "                with torch.no_grad():\n",
        "                    dev_predict = predict(rnn, dev_data, args)\n",
        "                pred_acc_p = score(dev_predict, dev_data.labels)\n",
        "                print(\"Epoch:%d\" % epoch)\n",
        "                print(\"[p:%.4f, r:%.4f, f:%.4f] acc:%.4f\" %\n",
        "                      (pred_acc_p[0], pred_acc_p[1], pred_acc_p[2], pred_acc_p[3]))\n",
        "                # with torch.no_grad():\n",
        "                #     test_predict = predict(rnn, test_data, args)\n",
        "                # pred_acc_t = score(test_predict, test_data.labels)\n",
        "                # print(\"[p:%.4f, r:%.4f, f:%.4f] acc:%.4f\" %\n",
        "                #       (pred_acc_t[0], pred_acc_t[1], pred_acc_t[2], pred_acc_t[3]))\n",
        "\n",
        "                if pred_acc_p[2] > max_acc:\n",
        "                    best_predict = dev_predict\n",
        "                    # label_prf = label_analysis(best_predict, test_data.labels)\n",
        "                    # for i in range(len(label_prf)):\n",
        "                    #     print(\"%s : [%.4f, %.4f, %.4f] %.4f\" %\n",
        "                    #           (list(attr_dict.keys())[i], label_prf[i][0], label_prf[i][1], label_prf[i][2], label_prf[i][3]))\n",
        "                    max_acc = pred_acc_p[2]\n",
        "                    max_print = (\"Epoch%d\\n\" % epoch\n",
        "                                 + \"[p:%.4f, r:%.4f, f:%.4f] acc:%.4f\\n\"\n",
        "                                 % (pred_acc_p[0], pred_acc_p[1], pred_acc_p[2], pred_acc_p[3]))\n",
        "                    best_model = \"%s/checkpoint_%s_%.6f.pt\" % (args.check_dir, args.model, max_acc)\n",
        "                    best_dict = copy.deepcopy(rnn)\n",
        "        # test_acc.append(pred_acc)\n",
        "        print(\"Epoch: %d, loss: %.4f\" % (epoch, loss_sum))\n",
        "\n",
        "    print(max_acc)\n",
        "    print(max_print)\n",
        "    label_prf = label_analysis(best_predict, test_data.labels)\n",
        "    for i in range(len(label_prf)):\n",
        "        print(\"%s : [%.4f, %.4f, %.4f] %.4f\" %\n",
        "              (list(attr_dict.keys())[i], label_prf[i][0], label_prf[i][1], label_prf[i][2], label_prf[i][3]))\n",
        "\n",
        "    # plt.figure()\n",
        "    plt.plot(all_losses)\n",
        "    time_stamp = time.asctime().replace(':', '_').split()\n",
        "    print(time_stamp)\n",
        "    plt.savefig(\"fig/foor_%s.png\" % '_'.join(time_stamp))\n",
        "    # plt.show()\n",
        "    return best_dict, max_acc\n",
        "  \n",
        "def optimize_step(rnn, input_tensors, category_tensor, optimizer):\n",
        "    rnn.zero_grad()\n",
        "    rnn.train()\n",
        "    output = rnn(input_tensors)\n",
        "    # print(output)\n",
        "\n",
        "    loss = F.multilabel_soft_margin_loss(output, category_tensor.float())\n",
        "    # loss = F.binary_cross_entropy(output, category_tensor.float())\n",
        "    # loss = customized_loss2(output, category_tensor.float())\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "def customized_loss2(input, target):\n",
        "    length = target.size()[1]\n",
        "    # print(length)\n",
        "    ones = target.sum()\n",
        "    zeros = target.size()[0] - ones\n",
        "    # print(input)\n",
        "    # print(target)\n",
        "    cks = torch.mul(input, target)\n",
        "\n",
        "    # print(\"fuck\")\n",
        "    # print(cks.size())\n",
        "    # print(cks.expand(length, length))\n",
        "    mask = torch.mm(target.view(-1,1), target.view(1,-1))\n",
        "    mask = 1 - mask\n",
        "    all_matrix = torch.mm(input.view(-1,1), target.view(1,-1))\n",
        "    all_matrix = torch.mul(all_matrix, mask)\n",
        "    ck_matrix = cks.expand(length, length)\n",
        "    ck_matrix = torch.mul(ck_matrix, mask)\n",
        "    sub = torch.exp(-(ck_matrix - all_matrix))\n",
        "    sub = torch.mul(sub, target.expand(length, length))\n",
        "    # print(all_matrix)\n",
        "    # print(sub)\n",
        "    sum = sub.sum() - ones**2\n",
        "    loss = sum/(ones*(length-ones))\n",
        "    # print(loss)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def category_from_output(output):\n",
        "\n",
        "    top_n, top_i = output.topk(1) # Tensor out of Variable with .data\n",
        "    # print(top_i)\n",
        "    category_i = top_i.view(output.size()[0]).detach()\n",
        "    return category_i\n",
        "\n",
        "\n",
        "def categories_from_output(output, threshold=[0.45 for _ in range(10)]):\n",
        "    # categories = []\n",
        "    predicted = [0 for i in range(output.size()[1])]\n",
        "    tensor = output.detach()\n",
        "    # print(output)\n",
        "    # print(tensor)\n",
        "\n",
        "    for i in range(tensor.size()[1]):\n",
        "        p = tensor[0, i]\n",
        "        # print(p)\n",
        "        if type(threshold) == list:\n",
        "            t = threshold[i]\n",
        "        else:\n",
        "            t = 0.45\n",
        "        if p > t:\n",
        "            predicted[i] = 1\n",
        "            # categories.append(attrC[i])\n",
        "\n",
        "    if sum(predicted) == 0:\n",
        "        predicted[tensor.argmax()] = 1\n",
        "\n",
        "    # if len(categories) < 1:\n",
        "    #     categories = [\"以上都不属于\"]\n",
        "    return predicted\n",
        "\n",
        "\n",
        "def predict(rnn, dev_data, args):\n",
        "    length = len(dev_data.sentences)\n",
        "    rnn.eval()\n",
        "    predicted_p = []\n",
        "    conflict = 0\n",
        "    for i in range(length):\n",
        "        # category_tensor = Variable(torch.LongTensor([dev_y[i] - 1]))\n",
        "        input_tensors, _ = dev_data.get(i, cuda_flag)\n",
        "        output_p = rnn(input_tensors)\n",
        "        # output_p = F.sigmoid(output_p)\n",
        "        # if args.model == 'CNN':\n",
        "        #     output_p = F.sigmoid(output_p)\n",
        "        category_i_p = categories_from_output(output_p)\n",
        "        # print(category_i_t)\n",
        "        # for k in range(len(category_i_t)):\n",
        "        #     if category_i_t[k] != 2 and category_i_p[k] != 2:\n",
        "        #         conflict += 1\n",
        "        #         if output_t.data[k][category_i_t[k]] > output_p.data[k][category_i_p[k]]:\n",
        "        #             category_i_p[k] = 2\n",
        "        #         else:\n",
        "        #             category_i_t[k] = 2\n",
        "        # exit(-1)\n",
        "        predicted_p.append(category_i_p)\n",
        "\n",
        "    return predicted_p\n",
        "\n",
        "def predict_with_logit(rnn, dev_data, args):\n",
        "    length = len(dev_data.sentences)\n",
        "    rnn.eval()\n",
        "    predicted_p = []\n",
        "    conflict = 0\n",
        "    class_num = 10\n",
        "    oof_dev = np.zeros((length, class_num))\n",
        "    for i in range(length):\n",
        "        # category_tensor = Variable(torch.LongTensor([dev_y[i] - 1]))\n",
        "        input_tensors, _ = dev_data.get(i, cuda_flag)\n",
        "        output_p = rnn(input_tensors)\n",
        "        oof_dev[i] = output_p[0].cpu().detach().numpy()\n",
        "        # output_p = F.sigmoid(output_p)\n",
        "        # if args.model == 'CNN':\n",
        "        #     output_p = F.sigmoid(output_p)\n",
        "        category_i_p = categories_from_output(output_p, args.threshold_list)\n",
        "\n",
        "        predicted_p.append(category_i_p)\n",
        "\n",
        "    return predicted_p, oof_dev\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjx0Ux3yaA8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttributeClassifier:  # Neural network method\n",
        "    def __init__(self):\n",
        "        self.classifier = None\n",
        "        self.trained = False\n",
        "        pass\n",
        "    def train_from_data(self, train_raw_data, test_raw_data, W, word2index, attr_dict, args, Fold=0):\n",
        "\n",
        "        word_embed_dim = W.shape[1]\n",
        "        hidden_size = args.n_hidden\n",
        "        vocab_size = len(W)\n",
        "        output_size = len(attr_dict)\n",
        "\n",
        "        if args.model == 'LSTM':\n",
        "            self.classifier = LSTM(word_embed_dim, output_size, vocab_size, args)\n",
        "        elif args.model == 'Fasttext':\n",
        "            self.classifier = Fasttext(word_embed_dim, output_size, vocab_size, args)\n",
        "        elif args.model == 'Average_LSTM2':\n",
        "            self.classifier = networks.Average_LSTM2(word_embed_dim, output_size, vocab_size, args)\n",
        "        elif args.model == 'AttA3':\n",
        "            self.classifier = networks.AttA3(word_embed_dim, output_size, vocab_size, args)\n",
        "            aspect_e_l = []\n",
        "            for a in attr_dict:\n",
        "                # print(a)\n",
        "                if a == '舒适性':\n",
        "                    a = '舒适'\n",
        "                a_e = torch.FloatTensor(W[word2index[a]])\n",
        "                aspect_e_l.append(a_e)\n",
        "            aspect_embeds = torch.cat(aspect_e_l, 0)\n",
        "            # print(aspect_embeds)\n",
        "            # print(attr_dict)\n",
        "            self.classifier.AE.weight = torch.nn.Parameter(aspect_embeds)\n",
        "        elif args.model == 'Binary_LSTM':\n",
        "            self.classifier = networks.Binary_LSTM(word_embed_dim, output_size, vocab_size, args)\n",
        "        elif args.model == 'CNN':\n",
        "            self.classifier = CNN(word_embed_dim, output_size, vocab_size, args)\n",
        "        elif args.model == 'Attn_LSTM':\n",
        "            self.classifier = networks.Attn_LSTM(word_embed_dim, output_size, vocab_size, args)\n",
        "\n",
        "        train_elmo, test_elmo = [], []\n",
        "\n",
        "        if args.use_elmo != 0:\n",
        "            import h5py\n",
        "            elmo_dict = h5py.File('../embedding/embeddings_elmo_ly-1.hdf5', 'r')\n",
        "            for s in train_raw_data[0]:\n",
        "                sentence = '\\t'.join(s)\n",
        "                sentence = sentence.replace('.', '$period$')\n",
        "                sentence = sentence.replace('/', '$backslash$')\n",
        "                # print(sentence)\n",
        "                embeddings = torch.from_numpy(np.asarray(elmo_dict[sentence]))\n",
        "                train_elmo.append(embeddings)\n",
        "            for s in test_raw_data[0]:\n",
        "                sentence = '\\t'.join(s)\n",
        "                sentence = sentence.replace('.', '$period$')\n",
        "                sentence = sentence.replace('/', '$backslash$')\n",
        "                embeddings = torch.from_numpy(np.asarray(elmo_dict[sentence]))\n",
        "                test_elmo.append(embeddings)\n",
        "            elmo_dict.close()\n",
        "            print(\"finish elmo\")\n",
        "\n",
        "        train_data = Data(train_raw_data, word2index, attr_dict, args)\n",
        "        # if args.use_dev:\n",
        "        #     dev_data = Data(args, dev_input_s, dev_input_t, dev_y_tensor)\n",
        "        # else:\n",
        "        #     dev_data = None\n",
        "        test_data = Data(test_raw_data, word2index, attr_dict, args)\n",
        "        if args.use_elmo != 0:\n",
        "            train_data.add_feature(train_elmo)\n",
        "            test_data.add_feature(test_elmo)\n",
        "        best_dict, max_acc = train(self.classifier, train_data, test_data, test_data, attr_dict, W, args=args)\n",
        "        best_model = \"%s/checkpoint_%s_%.6f_%d.pt\" % (args.check_dir, args.model, max_acc, Fold)\n",
        "        if args.save != 0:\n",
        "            torch.save(best_dict, best_model)\n",
        "        pass\n",
        "\n",
        "    def load_model(self, check_point):\n",
        "        self.classifier = torch.load(check_point)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyP-XQCeaAyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = AttributeClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlOj-8mQvT_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import copy\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiGwqjmT4GZn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "7a95d27f-21e1-4e40-ddf3-e0e26cd04115"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jan 30 14:35:16 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   77C    P0    34W /  70W |    949MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EERGdKR9aAkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "outputId": "30e6b5f8-b16a-4c60-e6fa-d6c6c969a109"
      },
      "source": [
        "# if not os.path.exists(\"%s\" % args.check_dir):\n",
        "#     os.mkdir(\"%s\" % args.check_dir)\n",
        "import os\n",
        "fig_dir = './fig'\n",
        "if not os.path.exists(fig_dir):\n",
        "  os.mkdir(fig_dir)\n",
        "model.train_from_data((train_texts, train_labels), (test_texts, test_labels), W, word2index, attr_dict, args)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN\n",
            "CUDA: True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:1\n",
            "[p:0.8655, r:0.8530, f:0.8592] acc:0.7798\n",
            "Epoch: 1, loss: 1027.7489\n",
            "Epoch:2\n",
            "[p:0.8000, r:0.8298, f:0.8146] acc:0.7085\n",
            "Epoch: 2, loss: 650.8678\n",
            "Epoch:3\n",
            "[p:0.8424, r:0.8390, f:0.8407] acc:0.7610\n",
            "Epoch: 3, loss: 472.5047\n",
            "Epoch:4\n",
            "[p:0.8186, r:0.8582, f:0.8379] acc:0.7390\n",
            "Epoch: 4, loss: 352.5205\n",
            "Epoch:5\n",
            "[p:0.8432, r:0.8634, f:0.8532] acc:0.7704\n",
            "Epoch: 5, loss: 288.4502\n",
            "0.8592174263816054\n",
            "Epoch1\n",
            "[p:0.8655, r:0.8530, f:0.8592] acc:0.7798\n",
            "\n",
            "动力 : [0.8780, 0.9059, 0.8917] 0.3244\n",
            "价格 : [0.9428, 0.9241, 0.9333] 0.1423\n",
            "内饰 : [0.8160, 0.8095, 0.8127] 0.0592\n",
            "配置 : [0.8848, 0.8048, 0.8429] 0.0986\n",
            "安全性 : [0.6882, 0.8533, 0.7619] 0.0704\n",
            "外观 : [0.9277, 0.6638, 0.7739] 0.0545\n",
            "操控 : [0.9009, 0.7326, 0.8081] 0.1282\n",
            "油耗 : [0.9132, 0.9427, 0.9277] 0.1310\n",
            "空间 : [0.8692, 0.9339, 0.9004] 0.0568\n",
            "舒适性 : [0.7611, 0.7544, 0.7577] 0.1070\n",
            "['Thu', 'Jan', '30', '14_48_27', '2020']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordRep. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv1d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZGmjE16T6p8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "cf79647d-127d-4c97-8ebb-9bdd53241614"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jan 30 14:32:15 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   77C    P0    34W /  70W |    949MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbrRo8qH2_MY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "b9ca1b13-2cb2-42c3-ad76-39daed2b3afe"
      },
      "source": [
        "ls"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \u001b[0m\u001b[01;34mattribute_level\u001b[0m/\n",
            "'【BDCI 2018】+汽车行业用户观点主题及情感识别+Just a test+答辩PPT.pdf'\n",
            " \u001b[01;34mbert\u001b[0m/\n",
            " \u001b[01;34mcheck_file\u001b[0m/\n",
            " \u001b[01;34mdata\u001b[0m/\n",
            " \u001b[01;34mdataset\u001b[0m/\n",
            " \u001b[01;34membedding\u001b[0m/\n",
            " \u001b[01;34mfig\u001b[0m/\n",
            " \u001b[01;34mpolarity_level_aspect\u001b[0m/\n",
            " ReadMe.md\n",
            " slides.pdf\n",
            " \u001b[01;34mutils\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIwZWKuc-o7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}